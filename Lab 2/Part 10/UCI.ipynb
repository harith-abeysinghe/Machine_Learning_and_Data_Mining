{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: '0.'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train[rIndex]\n\u001b[0;32m     37\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train[rIndex]\n\u001b[1;32m---> 38\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Separate features and labels for test data\u001b[39;00m\n\u001b[0;32m     41\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_data[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '0.'"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Load dataset from CSV\n",
        "dataset_file = \"clean2.data.csv\"  # Update with the path to your combined CSV file\n",
        "file_dataset = open(dataset_file, mode='r')\n",
        "csvreader_dataset = csv.reader(file_dataset)\n",
        "next(csvreader_dataset)  # Skip headers\n",
        "\n",
        "# Initialize lists to store training and test data\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "# Read data from CSV and separate into training and test data\n",
        "for i, row in enumerate(csvreader_dataset):\n",
        "    if i < 3600:\n",
        "        train_data.append(row)\n",
        "    else:\n",
        "        test_data.append(row)\n",
        "\n",
        "# Close CSV file\n",
        "file_dataset.close()\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_data = np.array(train_data)\n",
        "test_data = np.array(test_data)\n",
        "\n",
        "# Separate features and labels for training data\n",
        "X_train = train_data[:, 2:-1].astype(float)  # Assuming features start from column index 2 and end before the last column\n",
        "y_train = train_data[:, -1]\n",
        "rIndex = np.random.permutation(len(train_data))\n",
        "X_train = X_train[rIndex]\n",
        "y_train = y_train[rIndex]\n",
        "y_train = np.where(y_train==\"1.\", 1, -1)\n",
        "\n",
        "# Separate features and labels for test data\n",
        "X_test = test_data[:, 2:-1].astype(float)\n",
        "y_test = test_data[:, -1]\n",
        "y_test = np.where(y_test==\"1.\", 1, -1) \n",
        "\n",
        "\n",
        "# Display shapes of datasets\n",
        "print(\"Shape of training data (X_train):\", X_train.shape)\n",
        "print(\"Shape of training labels (y_train):\", y_train.shape)\n",
        "print(\"Shape of testing data (X_test):\", X_test.shape)\n",
        "print(\"Shape of testing labels (y_test):\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1 -1 -1 ... -1 -1 -1]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "print(y_train)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define PercentCorrect function\n",
        "def PercentCorrect(inputs, targets, weights):\n",
        "    N = len(targets)\n",
        "    targets = targets.astype(np.float64)\n",
        "    nCorrect = 0\n",
        "    for n in range(N):\n",
        "        oneInput = inputs[n, :]\n",
        "        if(targets[n] * np.dot(oneInput, weights) > 0):\n",
        "            nCorrect += 1\n",
        "    return 100 * nCorrect / N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Randomly generated weight vector (w): [ 0.85682687  1.80126352 -1.40314106 -1.49703777  0.04420332 -0.03484543\n",
            "  1.01812766  0.16996334 -1.8513496  -1.33607211 -0.43429325 -0.28697551\n",
            "  1.46962012 -0.55321996 -0.37628216 -0.51950743 -2.27699398  0.59508259\n",
            "  1.20716268  0.04191969 -0.65429985 -0.485753   -0.52950468 -0.69531487\n",
            "  2.1030207   0.95068824 -0.68137611  0.12089744 -0.47903021  0.95693207\n",
            " -1.47893515  1.22227053 -0.2617005  -0.53180298 -0.1811652   0.3609482\n",
            "  0.52316125 -0.84940391 -0.37280067 -0.04794134  0.41669512 -0.84608357\n",
            " -0.38254869 -1.68004501 -1.09963062  0.94245357 -0.55490458  0.16031281\n",
            "  0.0420231   1.04275915 -1.00254742  0.12228954 -0.84329008 -0.14757709\n",
            "  1.36872586  1.49861698 -0.93666581  0.65940122  0.61422422 -0.33047898\n",
            " -1.0203218   2.42504234 -1.36370657 -0.55070016  0.54471147 -0.93641188\n",
            "  0.3205577   0.05617774 -0.57656985 -0.33946526  1.37698075  0.05361287\n",
            "  0.80775541 -0.68670083 -0.46553188  0.37674656  1.05902874  0.07747134\n",
            "  0.85145642  0.74016215 -0.67739477  0.59315884  0.08752888 -0.30159102\n",
            "  1.56018447  0.11759212  0.35677329  0.20300081 -0.62898628 -0.97575709\n",
            " -1.32026031 -0.12224836  0.17348988  0.10050694 -1.64533096 -0.29362838\n",
            "  0.43544043  0.54216489  0.49072177  2.28935482 -0.74750444  0.30960124\n",
            " -0.62480494 -0.83623375 -0.99897559  1.18743889 -0.38579724 -0.56615963\n",
            "  1.00259231  0.00517009 -1.01550212 -1.54805787  1.91474865 -1.76948543\n",
            " -0.70613303 -0.96497755 -0.34520069  0.90822945 -0.94275167 -0.03243583\n",
            "  1.76287893 -3.50961068  1.48421079 -0.76264373 -0.93140808  0.96938495\n",
            " -0.35732756  0.63566088 -0.42046531 -0.76143662 -1.15805052 -1.04750196\n",
            "  1.58067818  1.09321205 -0.66595106  0.44418512  0.37507715  0.1373438\n",
            " -1.05985964 -0.94493409 -1.68210677  0.36438056 -0.69463605  0.03663286\n",
            "  0.68599207  0.26915271 -0.34189398 -0.43666961  0.035292    0.16109899\n",
            "  0.28063275 -0.26952569 -0.28760904  0.5766179   1.48215141  0.65180229\n",
            "  1.91007163  0.20940435 -2.35038103  1.11198046 -0.77777778 -0.46463587\n",
            " -0.20914919 -2.56469606  1.06829389 -1.70597812]\n",
            "Initial Percentage Correct:  36.08\n",
            "Percentage Correct After Training:  99.94 100.00\n"
          ]
        }
      ],
      "source": [
        "# Randomly initialize weights\n",
        "w = np.random.randn(X_train.shape[1])\n",
        "print(\"Randomly generated weight vector (w):\", w)\n",
        "\n",
        "# Print initial percentage correct\n",
        "print(\"Initial Percentage Correct: %6.2f\" % (PercentCorrect(X_train, y_train, w)))\n",
        "\n",
        "# Set parameters for training\n",
        "MaxIter = 2000\n",
        "alpha = 0.0001\n",
        "P_train = np.zeros(MaxIter)\n",
        "P_test = np.zeros(MaxIter)\n",
        "\n",
        "# Training loop\n",
        "Ntrain = X_train.shape[0]\n",
        "Ntest = X_test.shape[0]\n",
        "\n",
        "for iter in range(MaxIter):\n",
        "    r = np.floor(np.random.rand() * Ntrain).astype(int)\n",
        "    x = X_train[r, :]\n",
        "\n",
        "    if y_train[r] * np.dot(x, w) < 0:\n",
        "        w += alpha * y_train[r] * x\n",
        "\n",
        "    P_train[iter] = PercentCorrect(X_train, y_train, w)\n",
        "    P_test[iter] = PercentCorrect(X_test, y_test, w)\n",
        "\n",
        "# Print percentage correct after training\n",
        "print(\"Percentage Correct After Training: %6.2f %6.2f\" % (PercentCorrect(X_train, y_train, w), PercentCorrect(X_test, y_test, w)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
